{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br> <font color= 'green' size = 4> <b> NYC Parking Tickets - Analysis  </b> </font>\n",
    "\n",
    "</br> <font color ='blue'> Analyze NYC parking ticket data with Spark\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark Session\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PySpark DataFrame and Sql\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into dataframe 'df'\n",
    "df = spark.read.option(\"header\",\"true\").csv(\"/common_folder/nyc_parking/Parking_Violations_Issued_-_Fiscal_Year_2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration State|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|    5092469481| GZH7067|                NY|2016-07-10|             7|             SUBN|       TOYOT|                 0|              0|         0143A|\n",
      "|    5092451658| GZH7067|                NY|2016-07-08|             7|             SUBN|       TOYOT|                 0|              0|         0400P|\n",
      "|    4006265037| FZX9232|                NY|2016-08-23|             5|             SUBN|        FORD|                 0|              0|         0233P|\n",
      "|    8478629828| 66623ME|                NY|2017-06-14|            47|             REFG|       MITSU|                14|             14|         1120A|\n",
      "|    7868300310| 37033JV|                NY|2016-11-21|            69|             DELV|       INTER|                13|             13|         0555P|\n",
      "|    5096917368| FZD8593|                NY|2017-06-13|             7|             SUBN|       ME/BE|                 0|              0|         0852P|\n",
      "|    1413609545|  X20DCM|                NJ|2016-08-03|            40|              SDN|       TOYOT|                71|             71|         0215A|\n",
      "|    4628525523|  326SF9|                MA|2016-12-21|            36|               UT|         BMW|                 0|              0|         0758A|\n",
      "|    4627113330| HCA5464|                NY|2016-11-21|            36|             SUBN|       DODGE|                 0|              0|         1005A|\n",
      "|    4006478550| VAD7274|                VA|2016-10-05|             5|               4D|         BMW|                 0|              0|         0845A|\n",
      "|    1407740258| 2513JMG|                NY|2017-01-11|            78|             DELV|       FRUEH|               106|            106|         0015A|\n",
      "|    8009901763| 13657MD|                NY|2016-09-27|            19|             DELV|       KENWO|                18|             18|         0707A|\n",
      "|    4625926610|N102911C|                NY|2016-10-27|            36|              VAN|        FORD|                 0|              0|         1022A|\n",
      "|    1416492320| FGR5997|                NY|2016-09-30|            21|              SDN|       NISSA|                44|             44|         1150A|\n",
      "|    1413656420|T672371C|                NY|2017-02-04|            40|             TAXI|       TOYOT|                73|             73|         0525A|\n",
      "|    7959486440| GYF2052|                NY|2016-07-07|            71|             4DSD|       VOLKS|               120|            120|         0645P|\n",
      "|    5093620865| AD80228|                AZ|2016-09-24|             7|               TK|        FORD|                 0|              0|         1122A|\n",
      "|    8480309064| 51771JW|                NY|2017-01-26|            64|              VAN|       INTER|                17|             17|         0256P|\n",
      "|    1416638830|  GLP367|                NY|2017-04-30|            20|             SUBN|       DODGE|                17|             17|         1232A|\n",
      "|    4630524241|  HJBP29|                FL|2017-02-03|            36|               4D|         BMW|                 0|              0|         1034A|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the dataframe contents\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10803028"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of records in dataframe\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration State|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|             0|       0|                 0|         0|             0|                0|           0|                 0|              0|             0|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the null values in dataframe\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "df.select([count(when(isnan(c), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> Create sql view for the dataframe </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"sql_view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> select only the data from year 2017 </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = spark.sql(\"\"\"select * from sql_view where `Issue Date` like '2017%' \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Replace the sql view with latest data  </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017.createOrReplaceTempView(\"sql_view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examin the Data\n",
    "<B> 1. Find the total number of tickets for the year. </B>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|count(DISTINCT Summons Number)|\n",
      "+------------------------------+\n",
      "|                       5431918|\n",
      "+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select count(distinct(`Summons Number`)) from sql_view\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|count(Summons Number)|\n",
      "+---------------------+\n",
      "|              5431918|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select count((`Summons Number`)) from sql_view\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: There is no duplicate values present in the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> 2.1 Find out the number of unique states from where the cars that got parking tickets came. (Hint: Use the column 'Registration State'.) </B> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|unique_states|\n",
      "+-------------+\n",
      "|           65|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find out the number of unique states from where the cars that got parking tickets came\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"select count(distinct(`Registration State`)) as unique_states from sql_view\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> 2.2 There is a numeric entry '99' in the column, which should be corrected. Replace it with the state having the maximum entries. </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "|Registration State|number_of_entries|\n",
      "+------------------+-----------------+\n",
      "|                NY|          4273951|\n",
      "+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the state with maximum entries\n",
    "spark.sql(\"\"\"select `Registration State`,count(*) as number_of_entries from sql_view group by `Registration State` order by count(*) desc limit 1\"\"\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '99' with 'NY'\n",
    "df_2017_updated = df_2017.withColumn(\"Registration state\",when(df[\"Registration state\"] == '99','NY').otherwise(df[\"Registration state\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the sql view with new data\n",
    "df_2017_updated.createOrReplaceTempView(\"sql_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|unique_states|\n",
      "+-------------+\n",
      "|           64|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find out the number of unique states from where the cars that got parking tickets came after replacing the erreneous state '99'\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"select count(distinct(`Registration State`)) as unique_states from sql_view\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation tasks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. How often does each violation code occur? Display the frequency of the top five violation codes. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------------+\n",
      "|Violation Code|Violation_Code_Frequency|\n",
      "+--------------+------------------------+\n",
      "|            21|                  768087|\n",
      "|            36|                  662765|\n",
      "|            38|                  542079|\n",
      "|            14|                  476664|\n",
      "|            20|                  319646|\n",
      "+--------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select `Violation Code`,count(`Violation Code`) as Violation_Code_Frequency from sql_view group by `Violation Code` order by count(*) desc limit 5 \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2. How often does each 'vehicle body type' get a parking ticket? How about the 'vehicle make'?  </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------------+\n",
      "|vehicle body type|Vehicle_Body_Frequency|\n",
      "+-----------------+----------------------+\n",
      "|             SUBN|               1883954|\n",
      "|             4DSD|               1547312|\n",
      "|              VAN|                724029|\n",
      "|             DELV|                358984|\n",
      "|              SDN|                194197|\n",
      "+-----------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vehicle body type\n",
    "spark.sql(\"\"\"select `vehicle body type`,count(`vehicle body type`) as Vehicle_Body_Frequency from sql_view group by `vehicle body type` order by count(*) desc limit 5 \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------+\n",
      "|vehicle make|Vehicle_Make_Frequency|\n",
      "+------------+----------------------+\n",
      "|        FORD|                636844|\n",
      "|       TOYOT|                605291|\n",
      "|       HONDA|                538884|\n",
      "|       NISSA|                462017|\n",
      "|       CHEVR|                356032|\n",
      "+------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vehicle make\n",
    "spark.sql(\"\"\"select `vehicle make`,count(`vehicle make`) as Vehicle_Make_Frequency from sql_view group by `vehicle make` order by count(*) desc limit 5 \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 3.1 Find the top 5 tickets for Violation Precinct </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> note: Violation Precint entry with  '0'  values are erreneous records </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------------+\n",
      "|Violation Precinct|Violation_Precinct_Frequency|\n",
      "+------------------+----------------------------+\n",
      "|                 0|                      925596|\n",
      "|                19|                      274445|\n",
      "|                14|                      203553|\n",
      "|                 1|                      174702|\n",
      "|                18|                      169131|\n",
      "|               114|                      147444|\n",
      "+------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Top 5 tickets for violation precinct\n",
    "spark.sql(\"\"\"select `Violation Precinct`,count(`Violation Precinct`) as Violation_Precinct_Frequency from sql_view group by `Violation Precinct` order by count(*) desc limit 6 \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 3.2 Find the top 5 tickets for Issuer Precinct </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------------------+\n",
      "|Issuer Precinct|Violation_Precinct_Frequency|\n",
      "+---------------+----------------------------+\n",
      "|              0|                     1078406|\n",
      "|             19|                      266961|\n",
      "|             14|                      200495|\n",
      "|              1|                      168740|\n",
      "|             18|                      162994|\n",
      "|            114|                      144054|\n",
      "+---------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select `Issuer Precinct`,count(`Issuer Precinct`) as Violation_Precinct_Frequency from sql_view group by `Issuer Precinct` order by count(*) desc limit 6 \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Assumption:   Remove the erreneous records (records with precint entry '0')</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing erreneous records\n",
    "df_2017_updated1 = spark.sql(\"\"\"select * from sql_view where `Issuer Precinct` <> 0 and `Violation Precinct` <> 0\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the sql view with new data\n",
    "df_2017_updated1.createOrReplaceTempView(\"sql_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select count(*) from sql_view where `Violation Precinct` == 0\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select count(*) from sql_view where `Issuer Precinct` == 0\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 4. Find the violation code frequencies for three precincts that have issued the most number of tickets. Do these precinct zones have an exceptionally high frequency of certain violation codes? Are these codes common across precincts? </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 3 section , it can be noted that 19 , 14 , 1 are the top most precincts , find the voilation codes for these three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------------+\n",
      "|Violation Code|Violation_Precinct_Frequency|\n",
      "+--------------+----------------------------+\n",
      "|            46|                       50705|\n",
      "|            38|                       37482|\n",
      "|            37|                       36468|\n",
      "|            14|                       30330|\n",
      "|            21|                       28666|\n",
      "|            20|                       15087|\n",
      "|            40|                       11503|\n",
      "+--------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select `Violation Code`,count(`Violation Code`) as Violation_Precinct_Frequency from sql_view where `Violation Precinct` = 19 group by `Violation Code` order by count(*) desc  limit 7\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC_19 = {46,38,37,14,21,20,40}\n",
    "type(VC_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------------+\n",
      "|Violation Code|Violation_Precinct_Frequency|\n",
      "+--------------+----------------------------+\n",
      "|            14|                       45824|\n",
      "|            69|                       30464|\n",
      "|            31|                       22644|\n",
      "|            47|                       18655|\n",
      "|            42|                       10027|\n",
      "|            46|                        8400|\n",
      "|            19|                        7448|\n",
      "+--------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select `Violation Code`,count(`Violation Code`) as Violation_Precinct_Frequency from sql_view where `Violation Precinct` = 14 group by `Violation Code` order by count(*) desc limit 7 \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC_14 = {14,69,31,47,42,46,19}\n",
    "type(VC_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------------+\n",
      "|Violation Code|Violation_Precinct_Frequency|\n",
      "+--------------+----------------------------+\n",
      "|            14|                       38774|\n",
      "|            16|                       19131|\n",
      "|            20|                       15295|\n",
      "|            46|                       13434|\n",
      "|            38|                        8549|\n",
      "|            17|                        7575|\n",
      "|            37|                        6461|\n",
      "+--------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select `Violation Code`,count(`Violation Code`) as Violation_Precinct_Frequency from sql_view where `Violation Precinct` = 1 group by `Violation Code` order by count(*) desc limit 7   \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC_1 = {14,16,20,46,38,17,37}\n",
    "type(VC_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{14, 46}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1 = VC_19.intersection(VC_14)\n",
    "A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{14, 46}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2 = A1.intersection(VC_1)\n",
    "A2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> observation: Violation code with 14 and 46 have more number of entries created for Precincts 14,19 and 1 </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> 5. Find out the properties of parking violations across different times of the day:<B> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 5.1 Find a way to deal with missing values, if any.<b>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration State|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|             0|       0|                 0|         0|             0|                0|           0|                 0|              0|             0|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2017_updated1.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Observation: There are no null values observed in any column </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration state|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|    1404224350| FCJ5087|                NY|2017-05-04|            40|             SUBN|       NISSA|                70|            156|           nan|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select * from sql_view where `Violation Time` = 'nan' \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation : <B> Remove null values with string 'nan</B> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the rows with value 'nan'\n",
    "df_2017_updated2 = spark.sql(\"\"\"select * from sql_view where `Violation Time` <> 'nan' \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the new data\n",
    "df_2017_updated2.createOrReplaceTempView(\"sql_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration state|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the data after removing erreneous data\n",
    "\n",
    "spark.sql(\"\"\"select * from sql_view where `Violation Time` = 'nan' \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 5.2 The Violation Time field is specified in a strange format. Find a way to make this a time attribute that you can use to divide into groups.<b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|Violation Time|\n",
      "+--------------+\n",
      "|         1120A|\n",
      "|         0015A|\n",
      "|         0525A|\n",
      "|         0256P|\n",
      "|         1232A|\n",
      "|         1021A|\n",
      "|         0721A|\n",
      "|         0940A|\n",
      "|         1223P|\n",
      "|         1028A|\n",
      "+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify the Violation time records before modification\n",
    "spark.sql(\"\"\"select `Violation Time` from sql_view\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>  Change 12 hour format to 24 hour format by adding ':' between hours and minutes and also adding space with 'M' to time format </B> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+------------------+\n",
      "|Summons Number|Plate ID|Registration state|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|Violation Time new|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+------------------+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14|            47|             REFG|       MITSU|                14|             14|         1120A|            1120AM|\n",
      "|    1407740258| 2513JMG|                NY|2017-01-11|            78|             DELV|       FRUEH|               106|            106|         0015A|            0015AM|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add 'M' to timeformat to prepare it for conversion\n",
    "\n",
    "df_2017_updated3 = spark.sql(\"\"\"select *,concat(`Violation Time`,'M') as `Violation Time new` from sql_view\"\"\")\n",
    "df_2017_updated3.show(2)\n",
    "df_2017_updated3.createOrReplaceTempView(\"sql_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the old column and rename the new column\n",
    "df_2017_updated3 = df_2017_updated3.drop('Violation Time')\n",
    "\n",
    "df_2017_updated3 = df_2017_updated3.withColumnRenamed('Violation Time New','Violation Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration state|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14|            47|             REFG|       MITSU|                14|             14|        1120AM|\n",
      "|    1407740258| 2513JMG|                NY|2017-01-11|            78|             DELV|       FRUEH|               106|            106|        0015AM|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the records after renaming column \n",
    "df_2017_updated3.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration state|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14|            47|             REFG|       MITSU|                14|             14|      11:20 AM|\n",
      "|    1407740258| 2513JMG|                NY|2017-01-11|            78|             DELV|       FRUEH|               106|            106|      00:15 AM|\n",
      "|    1413656420|T672371C|                NY|2017-02-04|            40|             TAXI|       TOYOT|                73|             73|      05:25 AM|\n",
      "|    8480309064| 51771JW|                NY|2017-01-26|            64|              VAN|       INTER|                17|             17|      02:56 PM|\n",
      "|    1416638830|  GLP367|                NY|2017-04-30|            20|             SUBN|       DODGE|                17|             17|      12:32 AM|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change the format from 'hhmmaa'  to 'hh:mm aa'\n",
    "from pyspark.sql.functions import col, regexp_replace\n",
    "\n",
    "df_2017_updated3 = df_2017_updated3.withColumn(\"Violation Time\", regexp_replace(col(\"Violation Time\") ,  \"(\\\\d{2})(\\\\d{2})\" , \"$1:$2 \" ) )\n",
    "df_2017_updated3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the format from 12 hours to 24 hours\n",
    "from pyspark.sql.functions import unix_timestamp,from_unixtime\n",
    "\n",
    "df_2017_updated3 = df_2017_updated3.withColumn('Violation Time',from_unixtime(unix_timestamp(col(('Violation Time')), \"hh:mm aa\"), \"HH:mm\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration state|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14|            47|             REFG|       MITSU|                14|             14|         11:20|\n",
      "|    1407740258| 2513JMG|                NY|2017-01-11|            78|             DELV|       FRUEH|               106|            106|          null|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the new records\n",
    "df_2017_updated3.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to sql view\n",
    "df_2017_updated3.createOrReplaceTempView(\"sql_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|Violation Time|\n",
      "+--------------+\n",
      "|         11:20|\n",
      "|          null|\n",
      "|         05:25|\n",
      "|         14:56|\n",
      "|         00:32|\n",
      "|         10:21|\n",
      "|         07:21|\n",
      "|         09:40|\n",
      "|         12:23|\n",
      "|         10:28|\n",
      "|         01:48|\n",
      "|         12:06|\n",
      "|         13:41|\n",
      "|         08:20|\n",
      "|         10:43|\n",
      "|         14:04|\n",
      "|         08:53|\n",
      "|         10:26|\n",
      "|         11:52|\n",
      "|         10:31|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# There are null values present in the column \n",
    "spark.sql(\"\"\"select `Violation Time` from sql_view\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> Check the number of null values present in Violatio Time column , remove the null values if they are less compared to non null records </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   28397|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the number of null value records\n",
    "spark.sql(\"\"\"select count(*) from sql_view where `Violation Time` is null \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 4321761|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the number of non null value records\n",
    "spark.sql(\"\"\"select count(*) from sql_view where `Violation Time` is not null \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the null values from dataframe \n",
    "df_2017_updated3 = spark.sql(\"\"\"select * from sql_view where `Violation Time` is not null\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sql view \n",
    "df_2017_updated3.createOrReplaceTempView(\"sql_view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 5.3 Divide 24 hours into six equal discrete bins of time. Choose the intervals as you see fit. For each of these groups, find the three most commonly occurring violations. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide 24 hours into six equal discrete bins of time\n",
    "df_2017_updated3 = spark.sql(\"\"\"select *,case\n",
    "             when hour(`Violation Time`) between 0 and 4 then '0_to_4'\n",
    "             when hour(`Violation Time`) between 4 and 8 then '4_to_8'\n",
    "             when hour(`Violation Time`) between 8 and 12 then '8_to_12'\n",
    "             when hour(`Violation Time`) between 12 and 16 then '12_to_16'\n",
    "             when hour(`Violation Time`) between 16 and 20 then '16_to_20'\n",
    "             when hour(`Violation Time`) between 20 and 24 then '20_to_24'\n",
    "             end as Violation_Time_Intervels \n",
    "             FROM sql_view\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+------------------------+\n",
      "|Summons Number|Plate ID|Registration state|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|Violation_Time_Intervels|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+------------------------+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14|            47|             REFG|       MITSU|                14|             14|         11:20|                 8_to_12|\n",
      "|    1413656420|T672371C|                NY|2017-02-04|            40|             TAXI|       TOYOT|                73|             73|         05:25|                  4_to_8|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the records in the dataframe\n",
    "df_2017_updated3.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to sql view\n",
    "df_2017_updated3.createOrReplaceTempView(\"sql_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+------------------------+\n",
      "|Summons Number|Plate ID|Registration state|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|Violation_Time_Intervels|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+------------------------+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14|            47|             REFG|       MITSU|                14|             14|         11:20|                 8_to_12|\n",
      "|    1413656420|T672371C|                NY|2017-02-04|            40|             TAXI|       TOYOT|                73|             73|         05:25|                  4_to_8|\n",
      "|    8480309064| 51771JW|                NY|2017-01-26|            64|              VAN|       INTER|                17|             17|         14:56|                12_to_16|\n",
      "|    1416638830|  GLP367|                NY|2017-04-30|            20|             SUBN|       DODGE|                17|             17|         00:32|                  0_to_4|\n",
      "|    8505131836| 87155MA|                NY|2017-05-27|            38|              VAN|       CHEVR|                 1|              1|         10:21|                 8_to_12|\n",
      "|    8513520615| 77026MG|                NY|2017-05-31|            14|             TRAC|       VOLVO|                24|             24|         07:21|                  4_to_8|\n",
      "|    8556155431| HFB9919|                NY|2017-05-26|            75|             4DSD|       DODGE|               114|            114|         09:40|                 8_to_12|\n",
      "|    8483087236| 76822MH|                NY|2017-05-19|            10|             DELV|         HIN|                14|             14|         12:23|                 8_to_12|\n",
      "|    8513914599| 65572JU|                NY|2017-06-09|            69|              VAN|        FORD|                19|             19|         10:28|                 8_to_12|\n",
      "|    8357020770|  Y56DLT|                NJ|2017-01-20|            21|             4DSD|       CHEVR|               113|            113|         01:48|                  0_to_4|\n",
      "|    7047487591| 50741JZ|                NY|2017-04-13|            38|             UTIL|         GMC|               115|            115|         12:06|                 8_to_12|\n",
      "|    8122530205| 95139JC|                NY|2017-01-05|            48|             DELV|       INTER|                13|             13|         13:41|                12_to_16|\n",
      "|    8544889610| VVP9002|                VA|2017-06-14|            21|             4DSD|        AUDI|                72|             72|         08:20|                  4_to_8|\n",
      "|    8162054819|  EW866X|                NJ|2017-01-29|            68|             4DSD|       NISSA|                84|             84|         10:43|                 8_to_12|\n",
      "|    8506053195| 25868MB|                NY|2017-01-25|            51|              VAN|        FORD|                 1|              1|         14:04|                12_to_16|\n",
      "|    8534116519| CES6482|                NY|2017-06-12|             9|             SUBN|       TOYOT|                81|             81|         08:53|                  4_to_8|\n",
      "|    8479417420|  AT459E|                NJ|2017-04-13|            69|             DELV|       FRUEH|                14|             14|         10:26|                 8_to_12|\n",
      "|    8522218316| EFJ1721|                NY|2017-05-17|            37|             SUBN|       HONDA|                19|             19|         11:52|                 8_to_12|\n",
      "|    8482374059|  F96FBF|                NJ|2017-04-23|            14|             4DSD|       ME/BE|                14|             14|         10:31|                 8_to_12|\n",
      "|    8523051284| SH3ZBAD|                AL|2017-03-11|            38|             4DSD|       DODGE|                44|             44|         08:09|                  4_to_8|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2017_updated3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|violation_code|Violation_Time|\n",
      "+--------------+--------------+\n",
      "|            21|        0_to_4|\n",
      "|            40|        0_to_4|\n",
      "|            14|        0_to_4|\n",
      "|            14|      12_to_16|\n",
      "|            38|      12_to_16|\n",
      "|            37|      12_to_16|\n",
      "|            37|      16_to_20|\n",
      "|            14|      16_to_20|\n",
      "|            38|      16_to_20|\n",
      "|            38|      20_to_24|\n",
      "|            40|      20_to_24|\n",
      "|            14|      20_to_24|\n",
      "|            40|        4_to_8|\n",
      "|            21|        4_to_8|\n",
      "|            14|        4_to_8|\n",
      "|            38|       8_to_12|\n",
      "|            14|       8_to_12|\n",
      "|            21|       8_to_12|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For each of the time intervals (6 intervals ) find the most violations occuring \n",
    "spark.sql(\"\"\"select  violation_code,Violation_Time\n",
    "             FROM\n",
    "             (\n",
    "             (select `Violation Code` as violation_code ,  '0_to_4' as Violation_Time from sql_view\n",
    "             where   Violation_Time_Intervels = '0_to_4'\n",
    "             group by `Violation Code`\n",
    "             order by count(*) desc\n",
    "             limit 3)\n",
    "             UNION\n",
    "             (select `Violation Code` as violation_code ,  '4_to_8' as Violation_Time from sql_view\n",
    "             where   Violation_Time_Intervels =  '4_to_8'\n",
    "             group by `Violation Code`\n",
    "             order by count(*) desc\n",
    "             limit 3)\n",
    "              UNION\n",
    "             (select `Violation Code` as violation_code , '8_to_12' as Violation_Time  from sql_view\n",
    "             where   Violation_Time_Intervels =  '8_to_12'\n",
    "             group by `Violation Code`\n",
    "             order by count(*) desc\n",
    "             limit 3)\n",
    "              UNION\n",
    "             (select `Violation Code` as violation_code ,'12_to_16' as Violation_Time  from sql_view\n",
    "             where   Violation_Time_Intervels = '12_to_16'\n",
    "             group by `Violation Code`\n",
    "             order by count(*) desc\n",
    "             limit 3)\n",
    "              UNION\n",
    "             (select `Violation Code` as violation_code ,'16_to_20' as Violation_Time  from sql_view\n",
    "             where   Violation_Time_Intervels = '16_to_20'\n",
    "             group by `Violation Code`\n",
    "             order by count(*) desc\n",
    "             limit 3)\n",
    "              UNION\n",
    "             (select `Violation Code` as violation_code , '20_to_24' as Violation_Time from sql_view\n",
    "             where   Violation_Time_Intervels = '20_to_24'\n",
    "             group by `Violation Code`\n",
    "             order by count(*) desc\n",
    "             limit 3)\n",
    "             ) t\n",
    "             order by Violation_Time \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> Observatin:  It is observed that  violation code : 14 is present in all forms of the time frame </B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> 5.4 Now, try another direction. For the three most commonly occurring violation codes, find the most common time of the day (in terms of the bins from the previous part) </B>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Violation Code: string]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the top 3 violation codes\n",
    "spark.sql(\"\"\"select `Violation Code` from sql_view\n",
    "             group by `Violation Code`\n",
    "             order by count(*) desc\n",
    "             limit 3\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------+\n",
      "|Violation_Time_Intervels|Violation_Code|\n",
      "+------------------------+--------------+\n",
      "|                12_to_16|            14|\n",
      "|                 8_to_12|            14|\n",
      "|                  4_to_8|            14|\n",
      "|                 8_to_12|            21|\n",
      "|                  4_to_8|            21|\n",
      "|                  0_to_4|            21|\n",
      "|                16_to_20|            38|\n",
      "|                12_to_16|            38|\n",
      "|                 8_to_12|            38|\n",
      "+------------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For the three most commonly occurring violation codes, find the most common time of the day\n",
    "spark.sql(\"\"\"select Violation_Time_Intervels,Violation_Code\n",
    "             FROM\n",
    "             ((select Violation_Time_Intervels, '21' as Violation_Code from sql_view\n",
    "             where   `Violation Code` = 21\n",
    "             group by Violation_Time_Intervels\n",
    "             order by count(*) desc\n",
    "             limit 3)\n",
    "             UNION\n",
    "             (select Violation_Time_Intervels, '38' as Violation_Code from sql_view\n",
    "             where   `Violation Code` = 38\n",
    "             group by Violation_Time_Intervels\n",
    "             order by count(*) desc\n",
    "             limit 3)\n",
    "             UNION\n",
    "             (select Violation_Time_Intervels, '14' as Violation_Code from sql_view\n",
    "             where   `Violation Code` = 14\n",
    "             group by Violation_Time_Intervels\n",
    "             order by count(*) desc\n",
    "             limit 3))t\n",
    "             order by Violation_Code\n",
    "             \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> Observation: It is observed that the top violation codes occured commonly in 8 to 12 time frame </B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> 6.1 Divide the year into a certain number of seasons, and find the frequencies of tickets for each season.  </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide 24 hours into six equal discrete bins of time\n",
    "df_2017_updated3 = spark.sql(\"\"\"select *,case\n",
    "             when month(`Issue Date`) in (4,5,6) then 'Summer'\n",
    "             when month(`Issue Date`) in (7,8,9) then 'Rainy'\n",
    "             when month(`Issue Date`) in (10,11,12,1)  then 'Winter'\n",
    "             when month(`Issue Date`) in (2,3)  then 'Spring'\n",
    "             end as Seasons \n",
    "             FROM sql_view\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+------------------------+-------+\n",
      "|Summons Number|Plate ID|Registration state|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|Violation_Time_Intervels|Seasons|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+------------------------+-------+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14|            47|             REFG|       MITSU|                14|             14|         11:20|                 8_to_12| Summer|\n",
      "|    1413656420|T672371C|                NY|2017-02-04|            40|             TAXI|       TOYOT|                73|             73|         05:25|                  4_to_8| Spring|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+------------------------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the data after adding seasons\n",
    "df_2017_updated3.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the data with changes\n",
    "df_2017_updated3.createOrReplaceTempView(\"sql_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|Seasons|no_of_tickets|\n",
      "+-------+-------------+\n",
      "| Summer|      2217486|\n",
      "| Spring|      1422131|\n",
      "| Winter|       681355|\n",
      "|  Rainy|          789|\n",
      "+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the frequencies of tickets for each season.\n",
    "spark.sql(\"\"\"select Seasons , count(*) as no_of_tickets\n",
    "             from sql_view \n",
    "             group by Seasons\n",
    "             order by count(*) desc\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> Observation: There are more tickets in the summer than any other season  </B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> 6.2 Find the three most common violations for each of these seasons </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+------+\n",
      "|Violation_Code|Season|   cnt|\n",
      "+--------------+------+------+\n",
      "|            14|Spring|150925|\n",
      "|            38|Spring|191351|\n",
      "|            21|Spring|203643|\n",
      "|            38|Summer|254664|\n",
      "|            14|Summer|246673|\n",
      "|            21|Summer|329246|\n",
      "|            38|Winter| 95370|\n",
      "|            14|Winter| 70248|\n",
      "|            21|Winter| 98673|\n",
      "+--------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the three most common violations for each of these seasons.\n",
    "\n",
    "spark.sql(\"\"\"select Violation_Code,Season,cnt\n",
    "             FROM\n",
    "             ((select `Violation Code` as Violation_Code, 'Summer' as Season ,count(*) as cnt from sql_view\n",
    "             where   Seasons = 'Summer'\n",
    "             group by `Violation Code`\n",
    "             order by count(*) desc\n",
    "             limit 3)\n",
    "             UNION\n",
    "             (select `Violation Code` as Violation_Code, 'Spring' as Season,count(*) as cnt from sql_view\n",
    "             where   Seasons ='Spring'\n",
    "             group by `Violation Code`\n",
    "             order by count(*) desc\n",
    "             limit 3)\n",
    "             UNION\n",
    "             (select `Violation Code` as Violation_Code, 'Winter' as Season,count(*) as cnt from sql_view\n",
    "             where   Seasons = 'Winter'\n",
    "             group by `Violation Code`\n",
    "             order by count(*) desc\n",
    "             limit 3))t\n",
    "             order by Season\n",
    "             \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> Observation:  14 , 38 and 21 are the frequent violation codes </B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> 7.1 Find the total occurrences of the three most common violation codes. </B> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------+\n",
      "|Violation Code|number_of_tickets|\n",
      "+--------------+-----------------+\n",
      "|            21|           631584|\n",
      "|            38|           541392|\n",
      "|            14|           467927|\n",
      "+--------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select `Violation Code`,count(*) as number_of_tickets\n",
    "from sql_view\n",
    "group by `Violation Code`\n",
    "order by count(*) desc\n",
    "limit 3\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> 7.2 Fines associated for the codes 14 115 dollars , code 21 55 dollars , code 50 dollars </B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>7.3 find the total amount collected for the three violation codes with the maximum tickets </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+\n",
      "|Violation Code|total_money|\n",
      "+--------------+-----------+\n",
      "|            14|   53811605|\n",
      "|            21|   34737120|\n",
      "|            38|   27069600|\n",
      "+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select `Violation Code`, case \n",
    "when `Violation Code`=14 then count(*)*115\n",
    "when `Violation Code`=38 then count(*)*50\n",
    "when `Violation Code` = 21 then count(*)*55 end as total_money \n",
    "from sql_view\n",
    "group by `Violation Code`\n",
    "order by total_money desc\n",
    "limit 3\n",
    " \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: Code 14 has collected more amount of fines than others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> 7.4  What can you intuitively infer from these findings? </B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> Observation: As per above observation Standing or parking where standing is not allowed by sign, street marking or; traffic control device is route cause of high amount collection through ticket. </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
